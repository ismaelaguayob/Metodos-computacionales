"0",""
"0","# Esto nos sirve sobre todo para saber si se nos coló algún bloque de código"
"0",""
"0","# Seleccionamos solo la columna de texto que nos interesa"
"0","text_data <- datos_proc %>% select(post_content)"
"0",""
"0","# Tokenizamos el texto y lo dividimos en palabras"
"0","words <- datos_proc %>%"
"0","  unnest_tokens(word, post_content)"
"0",""
"0","# Cantidad de palabras extraídas"
"0",""
"0","nrow(words)"
"1","[1]"
"1"," 1028714"
"1","
"
"0","# Cargar palabras comunes en español"
"0","data(""stop_words"") # Cargar palabras comunes en inglés (desde tidytext)"
"0","stop_words_es <- tibble(word = c(""el"", ""la"", ""de"", ""y"", ""en"", ""que"", ""a"", ""los"", ""con"", ""por"", ""lee"", ""las"", ""para"", ""se"", ""es"", ""su"",  ""del"", ""una"", ""al"", ""como"", ""más"", ""lo"", ""este"", ""sus"", ""esta"", ""también"", ""entre"", ""fue"", ""han"", ""un"", ""sin"", ""sobre"", ""ya"", ""pero"", ""no"", ""muy"", ""si"", ""porque"", ""cuando"", ""desde"", ""todo"", ""son"", ""ha"", ""hay"", ""le"", ""ni"", ""cada"", ""me"", ""tanto"", ""hasta"", ""nos"", ""mi"", ""tus"", ""mis"", ""tengo"", ""tienes"", ""esa"", ""ese"", ""tan"", ""esa"", ""esos"", ""esa"", ""esas"", ""él"", ""ella"", ""ellos"", ""ellas"", ""nosotros"", ""vosotros"", ""vosotras"", ""ustedes"", ""uno"", ""una"", ""unos"", ""unas"", ""alguien"", ""quien"", ""cual"", ""cuales"", ""cualquier"", ""cualesquiera"", ""como"", ""donde"", ""cuanto"", ""demasiado"", ""poco"", ""menos"", ""casi"", ""algunos"", ""algunas"", ""aunque"", ""cuyo"", ""cuya"", ""cuyos"", ""cuyas"", ""ser"", ""haber"", ""estar"", ""tener"", ""hacer"", ""ir"", ""ver"", ""dar"", ""debe"", ""debido"", ""puede"", ""pues"", ""dicho"", ""hecho"", ""mientras"", ""luego"", ""además"", ""entonces"", ""así"", ""tal"", ""dicha"", ""mismo"", ""misma"", ""demás"", ""otro"", ""otra"", ""otros"", ""otras"", ""debería"", ""tendría"", ""podría"", ""menos"", ""cuándo"", ""dónde"",  ""qué"", ""quién"", ""cuyo"", ""la"", ""lo"", ""las"", ""que"", ""está"", ""según"", ""esto""))"
"0",""
"0","# Filtramos las stop words del texto"
"0","words_clean <- words %>%"
"0","  anti_join(stop_words, by = ""word"") %>%"
"0","  anti_join(stop_words_es, by = ""word"")"
"0",""
"0","# Calculamos frecuencia de palabras"
"0","word_counts <- words_clean %>%"
"0","  count(word, sort = TRUE)"
"0",""
"0","# Ver las 10 palabras más frecuentes"
"0","head(word_counts, 10)"
